resource "kubernetes_config_map" "lineage_stats" {
  metadata {
    name      = "lineage-stats"
    namespace = "uat01"

    labels = {
      app = "lineage-stats"
    }
  }

  data = {
    "application.conf" = "# This is the main configuration file the application. It uses the HOCON format.\n# You may change the configuration here to match you environment, \n# or include this file in a custom configuration file that you can pass\n# to the application using: -Dconfig.file={path_to_file}\n#\n# See: https://www.playframework.com/documentation/2.7.0/ConfigFile\n#      https://www.playframework.com/documentation/2.7.0/ProductionConfiguration\n\nplay {\n  # Configure which hosts are allowed to connect\n  # Pattern '.' means match all, which is not recommended in production!\n  # See https://www.playframework.com/documentation/2.7.0/AllowedHostsFilter\n  # filters.hosts.allowed = [\".\"]\n\n  modules.enabled += \"com.ac.lineage.stats.modules.MainModule\"\n  \n  modules.enabled += \"com.ac.authorization.AuthorizationModule\"\n  \n  # Remove if pidfile is required\n  server.pidfile.path = /dev/null\n\n  server.max-header-size = 64k\n  server.max-header-size = $${?MAX_HEADER_VALUE_LENGTH}\n  \n  http {\n    errorHandler = play.http.JsonHttpErrorHandler\n\n    secret.key = \"changeme\"\n    secret.key = $${?APPLICATION_SECRET}\n\n    parser {\n      maxMemoryBuffer = 128MB\n      maxMemoryBuffer = $${?PLAY_HTTP_PARSER_MAX_MEMORY_BUFFER}\n\n      maxDiskBuffer = 128MB\n      maxDiskBuffer = $${?PLAY_HTTP_PARSER_MAX_DISK_BUFFER}\n    }\n  }\n  \n  ws.timeout.request = 20 minutes\n  ws.timeout.request = $${?PLAY_WS_TIMEOUT_REQUEST}\n  \n  ws.timeout.idle = 10 minutes\n  ws.timeout.idle = $${?PLAY_WS_TIMEOUT_IDLE}\n\n  filters.csrf.header.bypassHeaders {\n    Csrf-Token = \"nocheck\"\n    Csrf-Token = $${?CSRF_TOKEN}\n  }\n\n  # disable the built in filters\n  http.filters = play.api.http.NoHttpFilters\n\n  filters {\n    contentType {\n      # If non empty, then requests will be checked if the content type is not in this list.\n      whiteList = [\"application/json\"]\n    }\n  }\n}\n\nakka.http.parsing.max-uri-length = 2k\nakka.http.parsing.max-uri-length = $${?MAX_URI_LENGTH}\n\nhttp {\n  address = \"0.0.0.0\"\n  address = $${?ADDRESS}\n\n  # to disable, set port to: disabled\n  port = 9000\n  port = $${?PORT}\n  port = $${?HTTP_PORT}\n}\n\nhttps.port=$${?HTTPS_PORT}\n\nplay.server.https.keyStore {\n  path = $${?HTTPS_KEY_STORE_PATH}\n  type = $${?HTTPS_KEY_STORE_TYPE}\n  password = $${?HTTPS_KEY_STORE_PASSWORD}\n  algorithm = $${?HTTPS_KEY_STORE_ALGORITHM}\n}\n\ncassandra {\n  contactPoints = [\"cassandra1.uat.acx-sandbox.net\"]\n\n  port = 9042\n  #port = $${?CASSANDRA_PORT}\n\n  createSchemaOnStartup = false\n  createSchemaOnStartup = $${?CASSANDRA_CREATE_SCHEMA}\n\n  schemaFile = \"/path/to/schema.cql\"\n  schemaFile = $${?CASSANDRA_SCHEMA_FILE}\n\n  keyspace = lineage_stats\n  keyspace = $${?CASSANDRA_KEYSPACE}\n\n  reconnectionPolicy {\n    # Possible types: [\"exponential\", \"constant\"]\n    type = \"exponential\"\n    type = $${?CASSANDRA_RECONNECTION_POLICY_TYPE}\n\n    # only used if type == \"exponential\"\n    baseDelayMs = 1000\n    baseDelayMs = $${?CASSANDRA_RECONNECTION_POLICY_BASE_DELAY}\n\n    maxDelayMs = 10000\n    maxDelayMs = $${?CASSANDRA_RECONNECTION_POLICY_MAX_DELAY}\n\n    # only used if type == \"constant\"\n    delayMs = 1000\n    delayMs = $${?CASSANDRA_RECONNECTION_POLICY_DELAY}\n  }\n\n  queryLogger {\n\n    # To enable query logging, set 'enabled' to true\n    #\n    # Important note: If set to enabled, make sure to adjust the logging \n    # framework to accept log messages from QueryLogger, through the logback \n    # configuration file.\n    # See: https://docs.datastax.com/en/developer/java-driver/3.7/manual/logging/\n    enabled = false\n\n    # value must be greater than zero\n    slowQueryLatencyThresholdMillis = 5000\n\n    # -1 means unlimited (use with care)\n    maxQueryStringLength = 500\n\n    # -1 means unlimited (use with care)\n    maxLoggedParameters = 50\n\n    # -1 means unlimited (use with care)\n    maxParameterValueLength = 50\n  }\n}\n\n# See https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing\nexecutors {\n\n  # Thread context for database operations\n  database-operations {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 9\n      fixed-pool-size = $${?DATABASE_THREAD_POOL}\n    }\n  }\n\n  scheduling {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 9\n      fixed-pool-size = $${?SCHEDULING_THREAD_POOL}\n    }\n  }\n\n  stats-aggregation {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 9\n      fixed-pool-size = $${?AGGREGATION_THREAD_POOL}\n    }\n  }\n  \n  tasks {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 9\n      fixed-pool-size = $${?TASK_THREAD_POOL}\n    }\n  }\n\n  lineage {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 9\n      fixed-pool-size = $${?LINEAGE_THREAD_POOL}\n    }\n  }\n}\n\nac.authentication {\n    enabled = false\n    enabled = $${?AUTHENTICATION_ENABLED}\n    keystore.file = \"conf/auth/keystore.jks\"\n    keystore.file = $${?KEYSTORE_FILE}\n    keystore.password = \"password\"\n    keystore.password = $${?KEYSTORE_PASSWORD}\n    key.alias = \"ac-authentication\"\n    key.alias = $${?KEY_ALIAS}\n\n    cipher.algorithm = \"SHA256withECDSA\"\n    rights.cookie.name = \"rights\"\n    password.expiration.enabled = false\n    rights.expiration.enabled = false\n}\n\nvalidation.ignoreUnknownProperties = true\n\nauthentication {\n  # Should be set to file containing the authentication tokens for:\n  # bdms, lineage, process tracking service and data sets service\n  cookieFile = /opt/ac/conf/cookies.txt\n  cookieFile = $${?AUTH_COOKIE_FILE}\n}\n\nservices {\n\n  bdms {\n    url = \"http://bdms-service:9000\"\n    url = $${?BASE_URL_BDMS}\n  }\n\n  datasets {\n    url = \"http://data-sets-service:9000\"\n    url = $${?BASE_URL_DATASETS}\n  }\n\n  lineage {\n    url = \"http://ac-dl-read:9000\"\n    url = $${?BASE_URL_LINEAGE}\n  }\n\n  processTracking {\n    url = \"http://process-tracking:8080\"\n    url = $${?BASE_URL_PROCESS_TRACKING}\n  }\n}\n\nmock {\n\n  # Not to be used in production.\n  # Do not set anything to true unless you know what you are doing!\n\n  database = false\n\n  services {\n    lineage = false\n    bdms = false\n    processTracking = false\n    datasets = false\n  }\n\n  resources {\n    path = \"test/resources\"\n  }\n}\n\nsnapshots {\n  write {\n    windowMaxHours = 1000\n    windowMaxHours = $${?MAX_HOURS_READ_WINDOW}\n  }\n  read {\n    windowMaxHours = 1000\n    windowMaxHours = $${?MAX_HOURS_WRITE_WINDOW}\n  }\n}"

    "application.ini" = "# Setting -X directly (-J is stripped)\n# -J-X\n\n-J-Xmx1G\n-J-Xms1G\n\n-J-XX:+UseG1GC\n-J-XX:+UseStringDeduplication\n-J-XX:+OptimizeStringConcat\n\n-J-XX:+HeapDumpOnOutOfMemoryError\n-J-XX:HeapDumpPath=/acx/heap/java_pid<pid>.hprof\n-J-XX:+UseGCOverheadLimit\n\n# Add additional jvm parameters\n# -Dkey=val"

    "cookies.txt" = "rights_0=W3sidXNlcklkIjoibGluZWFnZS1zdGF0cy1zZXJ2aWNlLXVzZXIiLCJzZXJ2aWNlTmFtZSI6IkJETVMuUkVBRC5BTllWSUVXIiwidGltZU9mSXNzdWUiOjE2MTM0OTM5NzQuNzA3MDAwMDAwLCJzaWduYXR1cmUiOiJNRVFDSUU4VmZaekgrR3V3ZUZCeTdFL3lFeGo3TjlsUFJ4VXBnK2JQYU1kdGVMamFBaUJGZUluOVFmT3Q5QW9VNVV0czMzVzFKZ0VDTWg5SnUyd3lZTGgyVkIwOW53PT0ifSx7InVzZXJJZCI6ImxpbmVhZ2Utc3RhdHMtc2VydmljZS11c2VyIiwic2VydmljZU5hbWUiOiJCRE1TLk1FVEEuUkVBRCIsInRpbWVPZklzc3VlIjoxNjEzNDkzOTc0LjcwNzAwMDAwMCwic2lnbmF0dXJlIjoiTUVVQ0lCeENJM3pRS3pGT2xPN2R0cXZxN1lKMURKSEl4cnNoTTljT3FEVytOYlpsQWlFQTcrdTBTM09kNFpYUjM3WkhybktZd0VaSXFkM200dXc0L011a0tWcmp1VjQ9In0seyJ1c2VySWQiOiJsaW5lYWdlLXN0YXRzLXNlcnZpY2UtdXNlciIsInNlcnZpY2VOYW1lIjoiQkRNUy5EQVRBLlJFQUQiLCJ0aW1lT2ZJc3N1ZSI6MTYxMzQ5Mzk3NC43MDcwMDAwMDAsInNpZ25hdHVyZSI6Ik1FVUNJUUMxMkFtQUUyOGMrVkRZMWxDZTRDNWNLbHI1alhHbitEN0FZNFdaaW9wTmRBSWdWR1lEZGlBRCs5TWQwSzh4ZEl2TXFKS0RMaFo3aWpsaDlTRSsreGN6cHFRPSJ9XQ==;rights=1"

    "logback.xml" = "<!-- https://www.playframework.com/documentation/latest/SettingsLogger -->\n<configuration>\n  <conversionRule conversionWord=\"coloredLevel\" converterClass=\"play.api.libs.logback.ColoredLevel\" />\n  <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n    <encoder>\n      <pattern>%date %coloredLevel %logger{15} - %message%n%xException{10}</pattern>\n    </encoder>\n  </appender>\n  <appender name=\"ASYNCSTDOUT\" class=\"ch.qos.logback.classic.AsyncAppender\">\n    <appender-ref ref=\"STDOUT\" />\n  </appender>\n  <logger name=\"play\" level=\"INFO\" />\n  <logger name=\"application\" level=\"INFO\" />\n  <logger name=\"com.ac.lineage.stats\" level=\"INFO\" />\n  <!--\n  Turn on slow query logging by setting this logger to DEBUG; \n  set level to TRACE to also log query parameters \n  -->\n  <logger name=\"com.datastax.driver.core.QueryLogger.SLOW\" level=\"OFF\" />\n  <!-- Off these ones as they are annoying, and anyway we manage configuration ourselves -->\n  <logger name=\"com.avaje.ebean.config.PropertyMapLoader\" level=\"OFF\" />\n  <logger name=\"com.avaje.ebeaninternal.server.core.XmlConfigLoader\" level=\"OFF\" />\n  <logger name=\"com.avaje.ebeaninternal.server.lib.BackgroundThread\" level=\"OFF\" />\n  <logger name=\"com.gargoylesoftware.htmlunit.javascript\" level=\"OFF\" />\n  <root level=\"WARN\">\n    <appender-ref ref=\"ASYNCSTDOUT\" />\n  </root>\n</configuration>"

    "schema.cql" = "CREATE KEYSPACE IF NOT EXISTS ops360uat01_lineage_stats WITH replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };\nCREATE TABLE IF NOT EXISTS ops360uat01_lineage_stats.stats (\n    dataset_id text,\n    snapshot_start timestamp,\n    snapshot_end timestamp,\n    dataview_name text,\n    datamodel_id text,\n    classview_name text,\n    class_id text,\n    attributeview_name text,\n    attribute_id text,\n    from_status_code int,\n    from_status_description text,\n    from_status_statename text,\n    to_status_code int,\n    to_status_description text,\n    to_status_statename text,\n    process_name text,\n    process_label text,\n    process_is_value_editable boolean,\n    process_requires_other_user boolean,\n    operator text,\n    operator_tag text,\n    avg_duration bigint,\n    first_occurrence timestamp,\n    last_occurrence timestamp,\n    max_duration bigint,\n    median_occurrence timestamp,\n    min_duration bigint,\n    total_occurrences int,\n    PRIMARY KEY (dataset_id, snapshot_start, snapshot_end, dataview_name, datamodel_id, classview_name, class_id, attributeview_name, attribute_id, from_status_code, from_status_description, from_status_statename, to_status_code, to_status_description, to_status_statename, process_name, process_label, process_is_value_editable, process_requires_other_user, operator, operator_tag)\n) WITH CLUSTERING ORDER BY (snapshot_start DESC, snapshot_end DESC, dataview_name ASC, datamodel_id ASC, classview_name ASC, class_id ASC, attributeview_name ASC, attribute_id ASC, from_status_code ASC, from_status_description ASC, from_status_statename ASC, to_status_code ASC, to_status_description ASC, to_status_statename ASC, process_name ASC, process_label ASC, process_is_value_editable ASC, process_requires_other_user ASC, operator ASC, operator_tag ASC)\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n    AND comment = ''\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n    AND crc_check_chance = 1.0\n    AND dclocal_read_repair_chance = 0.1\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 128\n    AND read_repair_chance = 0.0\n    AND speculative_retry = '99PERCENTILE';"
  }
}

