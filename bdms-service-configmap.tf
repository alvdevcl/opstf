resource "kubernetes_config_map" "bdms_service" {
  metadata {
    name      = "bdms-service"
    namespace = "ops360"

    labels = {
      app = "bdms-service"
    }
  }

  data = {
    "application.conf" = "# This is the main configuration file for the application.\n# https://www.playframework.com/documentation/latest/ConfigFile\nplay.http.secret.key = QCYtAnfkaZiwrNwnxIlR6CTfG3gf90Latabg5241ABR5W1uDFN\nplay.http.secret.key=$${?APPLICATION_SECRET_KEY}\nplay.filters{\n  enabled += play.filters.gzip.GzipFilter\n  hosts {\n    allowed = [\".\"]\n  }\n}\n\nplay.filters.disabled += play.filters.csrf.CSRFFilter\n\nplay.filters.csrf.header.bypassHeaders {\n  Csrf-Token = \"nocheck\"\n  Csrf-Token = $${?CSRF_TOKEN}\n}\n\nplay.http.errorHandler = \"com.ac.util.exception.handler.ErrorHandler\"\nplay.modules.enabled += \"com.ac.authorization.AuthorizationModule\"\nplay.modules.enabled += \"play.modules.swagger.SwaggerModule\"\nplay.modules.disabled += \"play.api.db.evolutions.EvolutionsModule\"\n# Use custom evolutions module to enable multiple database scripts (Oracle, PosgreSQL)\nplay.modules.enabled += \"com.ac.bdms.persistence.evolutions.EvolutionsModule\"\nplay.logger.includeConfigProperties=true\nplay.server.pidfile.path=$${?PIDFILE_PATH}\n\nac.bdms {\n  ac.bdms.converter.create-time-series-null-value = false\n  ac.bdms.converter.create-time-series-null-value = $${?CREATE-TIME-SERIES-NULL-VALUE}\n  // Supported Service implementations: \"ACServer\" and \"ACX\"\n  data.service.implementation=ACServer\n  data.service.implementation = $${?BDMS_SERVICE}\n  data.service.prime.modelclass-in-fundmstr = false\n  data.service.prime.modelclass-in-fundmstr = $${?BDMS_MODEL_CLASS_IN_FUNDMSTR}\n  # The max number of time-series records that can be fetched from Prime in a single request.\n  # Not applicable for ACX\n  data.service.prime.timeseries_result_set_limit = 500\n  data.service.prime.timeseries_result_set_limit = $${?BDMS_DATA_SERVICE_TIMESERIES_RECORDS_FETCH_LIMI}\n  data.loader.ado_ids_batch_size = 1000\n  data.loader.ado_ids_batch_size = $${?BDMS_DATA_LOADER_ADO_IDS_BATCH_SIZE}\n  input.date-time-format = \"yyyyMMdd'T'HHmmssZ\"\n  json {\n    classifications.schema.file = \"conf/schema/classifications-schema.json\"\n    domain-model.schema.file = \"conf/schema/domain-model-schema.json\"\n    domain-view.schema.file = \"conf/schema/domain-model-view.json\"\n    public-types.schema.file = \"conf/schema/public-types-schema.json\"\n    domain-models-dir = \"target/sample-model\"\n    domain-models-dir = $${?MODEL_FOLDER}\n  }\n  creation{\n    batch-size=100\n    retry-count=5\n    use-override=true\n    use-override=$${?USE_OVERRIDE}\n    default-template=\"BDMS_DEFAULT\"\n    default-template=$${?DEFAULT_TEMPLATE}\n  }\n  changelog.enabled = true\n  changelog.enabled = $${?CHANGELOG_ENABLED}\n  changelog.max.attributes-in-record = 10\n  changelog.max.attributes-in-record = $${?CHANGELOG_MAX_ATTRIBUTES_IN_RECORD}\n\n  #Supported property values: FILESYSTEM, ORACLE, POSTGRESQL\n  configuration.store = FILESYSTEM\n  configuration.store = $${?CONFIGURATION_STORE}\n  applog.dir = $${?LOGS_FOLDER}\n\n  pc_source_ados_attrid_default = null\n  pc_source_ados_attrid_default = $${?PC_SOURCE_ADOS_ATTRID_DEFAULT}\n\n  # BDMS instance unique identifier\n  instance.id = $${?BDMS_INSTANCE_ID}\n\n  # BDM data syncronization mode. The supported property values: NONE, PRIMARY, SECONDARY\n  sync.mode = \"NONE\"\n  sync.mode = $${?SYNC_MODE}\n}\n\n\nremote.services.lineage-service.host = $${?DATA_LINEAGE_SERVICE_BASE_URL}\nremote.services.lineage-service.auth-token = $${?DATA_LINEAGE_SERVICE_AUTH_TOKEN}\n\nremote.services.auth-service.host = $${?AUTH_SERVICE_URL}\n# The token must allow access the following services: AUTHENTICATION.DATAVIEWS and AUTHENTICATION.BPM\nremote.services.auth-service.auth-token = $${?AUTH_SERVICE_AUTH_TOKEN}\n\nremote.services.issue-service.host = $${?ISSUE_SERVICE_URL}\n\n  ##  The token must allow access the DCIS.ADMIN service\nremote.services.issue-service.auth-token = $${?ISSUE_SERVICE_AUTH_TOKEN}\n\nremote.services.dataset-service.host = $${?DATASET_SERVICE_URL}\n\nplay.evolutions.autocommit = true\nplay.evolutions.db.bdms.enabled = false\nplay.evolutions.db.bdms.enabled = $${?BDMS_DB_EVOLUTIONS_ENABLED}\nplay.evolutions.db.bdms.autoApply = true\nplay.evolutions.db.bdms.autoApply = $${?BDMS_DB_EVOLUTIONS_AUTO_APPLY}\n\n# supported values: Prime_PostgresPersistenceUnit, Prime_OraclePersistenceUnit\njpa.prime=Prime_OraclePersistenceUnit\njpa.prime=$${?PRIME_PERSISTENCE_UNIT}\n\n# supported values: BDMS_PostgresPersistenceUnit, BDMS_OraclePersistenceUnit\njpa.bdms=BDMS_PostgresPersistenceUnit\njpa.bdms=$${?BDMS_PERSISTENCE_UNIT}\n\ndb.default {\n  driver = oracle.jdbc.OracleDriver\n  driver = $${?DB_DRIVER}\n  url = $${?DB_URL}\n  logSql = true\n  jndiName=PrimeDS\n  username=$${?DB_USER}\n  password=$${?DB_PASSWORD}\n}\n\ndb.bdms {\n  driver = org.postgresql.Driver\n  driver = $${?BDMS_DB_DRIVER}\n  url = $${?BDMS_DB_URL}\n  logSql = true\n  jndiName = BDMS_DS\n  username = $${?BDMS_DB_USER}\n  password = $${?BDMS_DB_PASSWORD}\n}\n\nfixedConnectionPool = 10\n\n# Set Hikari to fixed size\nplay.db {\n  prototype {\n    hikaricp.minimumIdle = $${fixedConnectionPool}\n    hikaricp.maximumPoolSize = $${fixedConnectionPool}\n    hikaricp.idleTimeout = 60000\n    hikaricp.connectionTimeout = 60000\n    hikaricp.validationTimeout = 3000\n    hikaricp.loginTimeout = 5\n    hikaricp.maxLifetime = 60000\n  }\n}\n\ncontexts {\n  # Thread context for data service (Prime or ACX) queries\n  dataServiceQueryOperations {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 10\n      fixed-pool-size = $${?DATA_SERVICE_QUERY_THREAD_POOL_SIZE}\n    }\n  }\n\n  # Thread context for attribute value queries (Prime or ACX)\n  attributeValueQueryOperations {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 20\n      fixed-pool-size = $${?ATTRIBUTE_VALUES_QUERY_THREAD_POOL_SIZE}\n    }\n  }\n\n  # Thread context for attribute value updates (Prime or ACX)\n  attributeValueUpdateOperations {\n    executor = \"thread-pool-executor\"\n    throughput = 1\n    thread-pool-executor {\n      fixed-pool-size = 10\n      fixed-pool-size = $${?ATTRIBUTE_VALUES_UPDATE_THREAD_POOL_SIZE}\n    }\n  }\n}\n\nac.api {\n  host = $${?AC_HOST}\n  installation = $${?AC_INST}\n  user = $${?AC_USER}\n  password = $${?AC_PASSWORD}\n  queriesMax = 4\n  retryInitialInterval=$${?AC_CONNECTION_RETRY_INITIAL_INTERVAL}\n  retryMaxAttempts=$${?AC_CONNECTION_RETRY_MAX_ATTEMPTS}\n}\n\nac.authentication {\n  enabled = false\n  enabled = $${?AUTHENTICATION_ENABLED}\n  keystore.file = \"conf/auth/keystore.jks\"\n  keystore.file = $${?KEYSTORE_FILE}\n  keystore.password = $${?KEYSTORE_PASSWORD}\n  key.alias = \"ac-authentication\"\n  key.alias = $${?KEY_ALIAS}\n\n  cipher.algorithm = \"SHA256withECDSA\"\n  rights.cookie.name = \"rights\"\n  password.expiration.enabled = false\n  rights.expiration.enabled = false\n}\n\nakka.http {\n  parsing {\n    max-uri-length = 1m\n  }\n}\n\nplay.server.akka.max-header-value-length=1M\nplay.http.parser.maxMemoryBuffer=20MB\nplay.http.parser.maxDiskBuffer = 200MB\nparsers.anyContent.maxLength = 200MB\n\nswagger {\n  # to hide POST/PUT/DELETE end-points set the filter property to \"com.ac.bdms.ws.swagger.SwaggerPrivateApiSpecFilter\"\n  filter = \"com.ac.bdms.ws.swagger.SwaggerDefaultApiSpecFilter\"\n  filter = $${?SWAGGER_API_FILTER}\n  api {\n    host = \"\"\n    info {\n      title = \"BDMS API\"\n      license = \"Copyrights: Asset Control International B.V.\"\n      licenseUrl = \"https://www.asset-control.com\"\n    }\n  }\n}\n\n\nkafka {\n  broker = \"http://kafka-broker:9092\"\n  broker = $${?KAFKA_BROKER}\n  groupId = \"bdms_model_update_consumer_\"\n  groupId = $${?GROUP_ID}\n  model-updates-topic = \"bdms-model-updates\"\n  model-updates-topic = $${?MODEL_UPDATES_TOPIC}\n}\n\n\nsecret.name.prefix=\"bdms-secret.\"\nsecret.name.prefix=$${?SECRET_PREFIX}\nplay.application.loader = com.alveotech.services.config.ApplicationLoader\nswagger.filter = \"com.ac.bdms.swagger.CustomSpecFilter\"\n\n\nac.authentication.enabled = true\nplay.server.akka.max-header-value-length=16M\nplay.filters.disabled += play.filters.csrf.CSRFFilter\nplay.filters.disabled += play.filters.hosts.AllowedHostsFilter\nplay.filters.enabled +=play.filters.cors.CORSFilter\nplay.filters.hosts {\n  allowed = [\".\"]\n}\nac.bdms.creation.default-template=\"BDMS_INS_LSA\"\nswagger.api.basepath = \"/ac/\"\ncors {\n    # The path prefixes to filter.\n    pathPrefixes = [\"/\"]\n    # The allowed origins. If null, all origins are allowed.\n    allowedOrigins = null\n    # The allowed HTTP methods. If null, all methods are allowed\n    allowedHttpMethods = null\n    # The allowed HTTP headers. If null, all headers are allowed.\n    allowedHttpHeaders = null\n    # The exposed headers\n    exposedHeaders = []\n    # The maximum amount of time the CORS meta data should be cached by the client\n    preflightMaxAge = 1 hour\n    # Whether to serve forbidden origins as non-CORS requests\n    serveForbiddenOrigins = true\n}"

    "application.ini" = "# Setting -X directly (-J is stripped)\n# -J-X\n-J-Xmx3G\n-J-Xms3G\n\n-J-XX:+UseG1GC\n-J-XX:+UseStringDeduplication\n-J-XX:+OptimizeStringConcat\n\n-J-XX:+HeapDumpOnOutOfMemoryError\n-J-XX:HeapDumpPath=/acx/heap/java_pid<pid>.hprof\n-J-XX:+UseGCOverheadLimit\n\n# Add additional jvm parameters\n# -Dkey=val\n-Dplay.http.context=/\n-Dconfig.file=/opt/docker/conf/external/application.conf\n-Dlogger.file=/opt/docker/conf/external/logback.xml"

    "logback.xml" = "<configuration>\n\n  <conversionRule conversionWord=\"coloredLevel\" converterClass=\"play.api.libs.logback.ColoredLevel\" />\n\n  <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\">\n    <file>$${application.home:-.}/logs/application.log</file>\n    <encoder>\n      <pattern>%date [%level] from %logger in %thread - %message%n%xException</pattern>\n    </encoder>\n  </appender>\n\n  <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n    <encoder>\n      <pattern>%date %coloredLevel %logger{15} - %message%n%xException{10}</pattern>\n    </encoder>\n  </appender>\n\n  <appender name=\"ASYNCFILE\" class=\"ch.qos.logback.classic.AsyncAppender\">\n    <appender-ref ref=\"FILE\" />\n  </appender>\n\n  <appender name=\"ASYNCSTDOUT\" class=\"ch.qos.logback.classic.AsyncAppender\">\n    <appender-ref ref=\"STDOUT\" />\n  </appender>\n\n  <logger name=\"play\" level=\"DEBUG\" />\n  <logger name=\"application\" level=\"DEBUG\" />\n  <logger name=\"com.ac.bdms\" level=\"DEBUG\" />\n  <logger name=\"com.ac.api\" level=\"DEBUG\" />\n\n  <root level=\"INFO\">\n    <appender-ref ref=\"STDOUT\" />\n  </root>\n</configuration>"
  }
}

